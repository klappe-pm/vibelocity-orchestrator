
# Model Capabilities
## Local Models (20 models)

| Model               | Size  | RAM   | Best For                | Speed | Quality |
| ------------------- | ----- | ----- | ----------------------- | ----- | ------- |
| deepseek-r1:70b     | 42GB  | ~35GB | Ultimate reasoning      | ⚡     | ⭐⭐⭐⭐⭐   |
| codellama:34b       | 19GB  | ~30GB | Best code quality       | ⚡     | ⭐⭐⭐⭐⭐   |
| qwen2.5:32b         | 19GB  | ~25GB | Premium intelligence    | ⚡     | ⭐⭐⭐⭐⭐   |
| codellama:13b       | 7.4GB | ~12GB | High-quality code       | ⚡⚡    | ⭐⭐⭐⭐    |
| magicoder:7b        | 3.8GB | ~8GB  | Optimal code balance    | ⚡⚡    | ⭐⭐⭐⭐    |
| qwen3:8b            | 5.2GB | ~10GB | Multilingual, reasoning | ⚡⚡    | ⭐⭐⭐⭐    |
| llama3.1:8b         | 4.9GB | ~8GB  | General tasks           | ⚡⚡    | ⭐⭐⭐     |
| llama3.2:3b         | 2.0GB | ~4GB  | Fast conversations      | ⚡⚡⚡   | ⭐⭐⭐     |
| deepseek-coder:1.3b | 776MB | ~2GB  | Quick code snippets     | ⚡⚡⚡   | ⭐⭐⭐     |
| gemma:7b            | 5.0GB | ~8GB  | Google's balanced model | ⚡⚡    | ⭐⭐⭐⭐    |
| qwen2.5:7b-instruct | 4.7GB | ~8GB  | Instruction-tuned Qwen  | ⚡⚡    | ⭐⭐⭐⭐    |

## OpenAI Models (11 models)

|Model|Context|Best For|Cost (I/O) per M tokens|
|---|---|---|---|
|o1-pro|200K|Ultimate reasoning|$60/$240|
|o1|200K|Deep reasoning|$15/$60|
|o1-mini|200K|Balanced reasoning|$3/$12|
|gpt-4o|128K|Vision, balanced tasks|$5/$15|
|gpt-4-turbo|128K|Vision, function calling|$10/$30|
|gpt-4|8K|Complex reasoning|$30/$60|
|gpt-4o-mini|128K|Fast, cost-effective|$0.15/$0.6|
|gpt-3.5-turbo|16K|Quick tasks|$0.5/$1.5|

### Bedrock Models (8 models)

|Model|Context|Best For|Cost (I/O) per M tokens|
|---|---|---|---|
|bedrock-claude-3-opus|200K|Premium reasoning|$15/$75|
|bedrock-claude-3.5-sonnet|200K|Balanced Claude|$3/$15|
|bedrock-llama-3.1-405b|32K|Massive model power|$5.32/$16|
|bedrock-llama-3.1-70b|32K|Strong reasoning|$2.65/$3.5|
|bedrock-titan-text-express|8K|AWS native|$0.8/$1.6|

### Anthropic Models (7 models)

|Model|Context|Best For|Cost (I/O) per M tokens|
|---|---|---|---|
|claude-opus-4.1|200K|Top reasoning|$20/$100|
|claude-opus-4|200K|Premium Claude|$15/$75|
|claude-sonnet-4.5|200K|Latest balanced|$4/$20|
|claude-sonnet-4|200K|Balanced tasks|$3/$15|
|claude-3-opus|200K|Previous gen premium|$15/$75|
|claude-3.5-sonnet|200K|Popular balanced|$3/$15|
|claude-3-haiku|200K|Fast, cost-effective|$0.25/$1.25|

### Google Gemini (6 models)

|Model|Context|Best For|Cost (I/O) per M tokens|
|---|---|---|---|
|gemini-2.0-pro|2M|Research, analysis|$1.5/$6|
|gemini-2.0-flash|1M|Fast responses|$0.1/$0.4|
|gemini-1.5-pro|2M|Previous gen pro|$1.25/$5|
|gemini-1.5-flash|1M|Previous gen flash|$0.075/$0.3|

### xAI Grok (5 models)

|Model|Context|Best For|Cost (I/O) per M tokens|
|---|---|---|---|
|grok-4-fast-reasoning|2M|Complex reasoning|$2/$6|
|grok-4-fast-non-reasoning|2M|Fast processing|$1/$3|
|grok-code-fast-1|256K|Code generation|$1.5/$4.5|
|grok-3|131K|General tasks|$1/$3|
|grok-2-vision-1212|32K|Image analysis|$2/$6|

### Azure OpenAI (4 models)

|Model|Context|Best For|Cost (I/O) per M tokens|
|---|---|---|---|
|azure-gpt-4o|128K|Enterprise GPT-4o|$5/$15|
|azure-gpt-4-turbo|128K|Enterprise GPT-4 Turbo|$10/$30|
|azure-gpt-4|8K|Enterprise GPT-4|$30/$60|
|azure-claude-3.5-sonnet|200K|Enterprise Claude|$3/$15|

### DIAL Gateway (2 models)

|Model|Context|Best For|Cost (I/O) per M tokens|
|---|---|---|---|
|dial-claude-opus-4|200K|Enterprise access|$15/$75|
|dial-claude-sonnet-4|200K|Enterprise balanced|$3/$15|
